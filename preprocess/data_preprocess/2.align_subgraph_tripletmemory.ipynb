{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import copy\n",
    "import h5py\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/soulofshadow/Downloads/Project'\n",
    "\n",
    "os.chdir(path)\n",
    "sys.path.append(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(path + '/data/text_to_entity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['entity'] = dataset['entity'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for read triplet from UMLS.RRF, just need once to generate umls_triplet.csv file for later use\n",
    "\n",
    "from utils.load_umls import UMLS\n",
    "umls = UMLS(path + '/data')\n",
    "\n",
    "#build the triplets\n",
    "umls_triplet = []\n",
    "\n",
    "for rel in umls.rel:\n",
    "    triplet = rel.strip().split(\"\\t\")\n",
    "    if len(triplet) != 4:\n",
    "        continue;\n",
    "\n",
    "    head = triplet[0]\n",
    "    tail= triplet[1]\n",
    "    relation = triplet[3]\n",
    "\n",
    "    tri = [head, tail, relation]\n",
    "    umls_triplet.append(tri)\n",
    "\n",
    "print(\"triplets count:\", len(umls_triplet))\n",
    "\n",
    "umls_triplet = pd.DataFrame(umls_triplet)\n",
    "umls_triplet.columns = ['head', 'tail', 'relation']\n",
    "umls_triplet.drop_duplicates()\n",
    "\n",
    "umls_triplet.to_csv(path + '/data/umls_triplet.csv', index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfer from str CUI to int CUI\n",
    "#like \"C1022345\" to 1022345\n",
    "def tran_to_index(x):\n",
    "    if not isinstance(x, int):\n",
    "        return int(x[1:])\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "#read umls relations\n",
    "umls_triplets = pd.read_csv(path + '/data/build_tri/umls_triplet.csv')\n",
    "\n",
    "\n",
    "umls_triplets['head'] = umls_triplets['head'].map(tran_to_index)\n",
    "umls_triplets['tail'] = umls_triplets['tail'].map(tran_to_index)\n",
    "\n",
    "dict_triplets = dict(zip(zip(umls_triplets['head'], umls_triplets['tail']), umls_triplets['relation']))\n",
    "\n",
    "print(\"triplets count:\", len(umls_triplets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>tail</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>934536</td>\n",
       "      <td>505381</td>\n",
       "      <td>inverse_isa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11008</td>\n",
       "      <td>943468</td>\n",
       "      <td>has_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60617</td>\n",
       "      <td>533932</td>\n",
       "      <td>mapped_to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1442351</td>\n",
       "      <td>486234</td>\n",
       "      <td>has_system</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2700007</td>\n",
       "      <td>1514011</td>\n",
       "      <td>is_abnormal_cell_of_disease</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      head     tail                     relation\n",
       "0   934536   505381                  inverse_isa\n",
       "1    11008   943468                has_component\n",
       "2    60617   533932                    mapped_to\n",
       "3  1442351   486234                   has_system\n",
       "4  2700007  1514011  is_abnormal_cell_of_disease"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umls_triplets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are total 608 kinds of relationship\n"
     ]
    }
   ],
   "source": [
    "# Define the relations_map\n",
    "umls_relations = set(umls_triplets['relation'])\n",
    "relations_map = {i: relation for i, relation in enumerate(umls_relations)}\n",
    "relations_r_map = {v:k for k,v in relations_map.items()}\n",
    "\n",
    "print(\"There are total {} kinds of relationship\".format(len(umls_relations)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:01, 21.65it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset['triplet'] = None\n",
    "\n",
    "build_entities = {}\n",
    "build_triplets = set()\n",
    "build_cui_triplets = set()\n",
    "\n",
    "for index, item in tqdm(dataset.iterrows()):\n",
    "\n",
    "    entities = copy.deepcopy(item['entity'])\n",
    "\n",
    "    for entity in entities:\n",
    "        entity['cui'] = tran_to_index(entity['cui'])\n",
    "        if entity['cui'] not in build_entities.keys():\n",
    "            build_entities[entity['cui']] = entity['preferred_name']\n",
    "\n",
    "    #start to align text with tripltes of umls\n",
    "    aligned_triplets = []\n",
    "    for entity1 in entities:\n",
    "        for entity2 in entities:\n",
    "            # we use a pair of entitis to detect whether they have a relation in the UMLS triplets\n",
    "            if entity1['cui'] != entity2['cui']:\n",
    "                if (entity1['cui'], entity2['cui']) in dict_triplets.keys():\n",
    "                    #we find one, we use this triplet to label this row\n",
    "                    #instead of store cui, we stored the string name of this entity\n",
    "                    rel = dict_triplets[(entity1['cui'], entity2['cui'])]\n",
    "\n",
    "                    cui_triplet = [entity1['cui'], relations_r_map[rel], entity2['cui']]\n",
    "                    triplet = [entity1['preferred_name'], rel, entity2['preferred_name']]\n",
    "\n",
    "                    build_cui_triplets.add(tuple(cui_triplet))\n",
    "                    build_triplets.add(tuple(triplet))\n",
    "                    aligned_triplets.append(triplet)\n",
    "    #Align\n",
    "    item['triplet'] = aligned_triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result\n",
    "\n",
    "with open(path + \"/data/build_tri/build_entities.json\", \"w\") as json_file:\n",
    "    json.dump(build_entities, json_file)\n",
    "\n",
    "with open(path + \"/data/build_tri/build_triplets.json\", \"w\") as json_file:\n",
    "    json.dump(list(build_triplets), json_file)\n",
    "\n",
    "with open(path + \"/data/build_tri/build_cui_triplets.json\", \"w\") as json_file:\n",
    "    json.dump(list(build_cui_triplets), json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get triplets \n",
    "\n",
    "triplets = [' '.join(triplet.split('_')) for triplet in build_triplets]\n",
    "\n",
    "with open(path + \"/data/triplets.json\", \"w\") as json_file:\n",
    "    json.dump(triplets, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read entity and triplet\n",
    "\n",
    "with open(path + \"/data/build_tri/build_entities.json\", \"r\") as json_file:\n",
    "    build_entities = json.load(json_file)\n",
    "    build_entities = {int(key):value for key, value in build_entities.items()}\n",
    "\n",
    "with open(path + \"/data/build_tri/build_triplets.json\", \"r\") as json_file:\n",
    "    build_triplets = json.load(json_file)\n",
    "\n",
    "with open(path + \"/data/build_tri/build_cui_triplets.json\", \"r\") as json_file:\n",
    "    build_cui_triplets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Here is for build rel_pairs as dict\n",
    "{(rel1, rel2) : count}\n",
    "'''\n",
    "rel_pairs = {}\n",
    "\n",
    "def count_rel_pairs(triplets):\n",
    "    #for better match speed, map it to index\n",
    "    rels = [relations_r_map[triplet[1]] for triplet in triplets]\n",
    "\n",
    "    length = len(rels)\n",
    "    for i in range(length):\n",
    "        rel_i = rels[i]\n",
    "        if i == length - 1:\n",
    "            break;\n",
    "        for j in range(i+1, length):\n",
    "            rel_j = rels[j]\n",
    "            if ((rel_i, rel_j) in rel_pairs.keys() or (rel_j, rel_i) in rel_pairs.keys()) and (rel_i != rel_j):\n",
    "                if (rel_i, rel_j) in rel_pairs.keys():\n",
    "                    rel_pairs[(rel_i, rel_j)] += 1\n",
    "                else:\n",
    "                    rel_pairs[(rel_j, rel_i)] += 1\n",
    "            else:\n",
    "                rel_pairs[(rel_i, rel_j)] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27it [00:00, 9733.24it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, item in tqdm(dataset.iterrows()):\n",
    "\n",
    "    triplets = item['triplet'] #column 3\n",
    "    if triplets is None:\n",
    "        continue\n",
    "\n",
    "    count_rel_pairs(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "\n",
    "#Trun to a dict of\n",
    "#key as rel\n",
    "#value as heapq of tuple (count, rel_2)\n",
    "# rel_pairs = sorted(rel_pairs.items(), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "dict_of_maxheap = {}\n",
    "\n",
    "for pairs, count in rel_pairs.items():\n",
    "    rel_i = pairs[0]\n",
    "    rel_j = pairs[1]\n",
    "\n",
    "    if rel_i not in dict_of_maxheap.keys():\n",
    "        heap = []\n",
    "        heapq.heappush(heap, (-count, rel_j))\n",
    "        dict_of_maxheap[rel_i] = heap\n",
    "    else:\n",
    "        heapq.heappush(dict_of_maxheap[rel_i], (-count, rel_j))\n",
    "\n",
    "    if rel_j not in dict_of_maxheap.keys():\n",
    "        heap = []\n",
    "        heapq.heappush(heap, (-count, rel_i))\n",
    "        dict_of_maxheap[rel_j] = heap\n",
    "    else:\n",
    "        heapq.heappush(dict_of_maxheap[rel_j], (-count, rel_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPTH = 5\n",
    "\n",
    "def map_to_string(triplet):\n",
    "\n",
    "    head = build_entities[triplet[0]]\n",
    "    tail = build_entities[triplet[2]]\n",
    "    rel = relations_map[triplet[1]]\n",
    "    return (head, rel, tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities = []\n",
    "all_triplet_sets = []\n",
    "\n",
    "for cui, name in build_entities.items():\n",
    "\n",
    "    retrievl = [] # R\n",
    "    for triplet in build_cui_triplets:\n",
    "        if cui == triplet[0]:\n",
    "            retrievl.append(triplet)\n",
    "\n",
    "    #cause Each entity subgraph consists of a maximum of five triples\n",
    "    #so if the triplet in the whole KG of this entity <= 5, we don't search for rel_pairs\n",
    "    #just add, and pass\n",
    "    if len(retrievl) <= 5:\n",
    "        if len(retrievl) != 0:\n",
    "            #transfer from int to string of name\n",
    "            triplet_set = []\n",
    "            for r in retrievl:\n",
    "                triplet_set.append(map_to_string(r))\n",
    "                build_cui_triplets.remove(r)\n",
    "            all_entities.append(name)\n",
    "            all_triplet_sets.append(triplet_set)\n",
    "        continue;\n",
    "\n",
    "    #if there are more than 5, we need to select those Rel by the rel_pair of the order of count\n",
    "    while retrievl:\n",
    "        triplet_set = []\n",
    "\n",
    "        triplet_random = random.choice(retrievl)\n",
    "        rel_random = triplet_random[1]\n",
    "        triplet_set.append(map_to_string(triplet_random))\n",
    "\n",
    "        retrievl.remove(triplet_random)\n",
    "        build_cui_triplets.remove(triplet_random)\n",
    "\n",
    "        for i in range(2, DEPTH):\n",
    "            maxheap = dict_of_maxheap[rel_random]\n",
    "            while maxheap:\n",
    "                max_element = heapq.heappop(maxheap)\n",
    "                flag = 0\n",
    "                for triplet in retrievl:\n",
    "                    if triplet[1] == max_element[1]:\n",
    "                        rel_random = max_element[1]\n",
    "                        triplet_set.append(map_to_string(triplet))\n",
    "                        retrievl.remove(triplet)\n",
    "                        build_cui_triplets.remove(triplet)\n",
    "                        flag = 1\n",
    "                        break;\n",
    "                if flag == 1:\n",
    "                    break;\n",
    "\n",
    "        if len(triplet_set) != 0:\n",
    "            all_entities.append(name)\n",
    "            all_triplet_sets.append(triplet_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result\n",
    "combine = {'entity':all_entities,\n",
    "           'subgraph':all_triplet_sets\n",
    "        }\n",
    "\n",
    "entity_subgraph = pd.DataFrame(combine)\n",
    "entity_subgraph.to_csv('data/entity_to_subgraph.csv', index_label=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save triplet memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path + \"/data/build_tri/build_entities.json\", \"r\") as json_file:\n",
    "    entities = json.load(json_file)\n",
    "\n",
    "with open(path + \"/data/build_tri/build_triplets.json\", \"r\") as json_file:\n",
    "    triplets = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for key, ent in tqdm(entities.items()):\n",
    "    related_triplet = [x for x in triplets if x[0] == ent]\n",
    "    if related_triplet:\n",
    "        sentence = \"\"\n",
    "        temp = 0\n",
    "        for triplet in related_triplet:\n",
    "            if temp == 0:\n",
    "                sentence = ' '.join(triplet)\n",
    "                temp = 1\n",
    "            else:\n",
    "                sentence += ', '\n",
    "                sentence += ' '.join(triplet[1:])\n",
    "        sentences.append([ent, sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.DataFrame(columns=['entity', 'serialized_sentence'], data=sentences)\n",
    "t_df.to_csv('data/memories/triplets_memory.csv',index_label=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
